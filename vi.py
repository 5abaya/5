import requests
from bs4 import BeautifulSoup
import time

url = "https://www.redbubble.com/sitemap/popular_fitted-mask_00000.xml"
response = requests.get(url)

if response.status_code == 200:
    sitemap_xml = response.content
    sitemap_soup = BeautifulSoup(sitemap_xml, "xml")

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø¹Ù†Ø§ÙˆÙŠÙ† URL Ù…Ù† Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹
    product_urls = [loc.text for loc in sitemap_soup.find_all("loc")] 
    last_modified_dates = [lastmod.text for lastmod in sitemap_soup.find_all("lastmod")] 

    # ØªØ¹ÙŠÙŠÙ† Ø­Ø¬Ù… Ø§Ù„Ø¬Ø²Ø¡
    chunk_size = 5 

    # ÙØªØ­ Ø§Ù„Ù…Ù„Ù Ù„Ù„ÙƒØªØ§Ø¨Ø©
    with open("output.txt", "w") as f:
        # ØªÙƒØ±Ø§Ø± ÙƒÙ„ URL ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
        for i in range(len(product_urls)): 
            product_url = product_urls[i] 
            last_modified_date = last_modified_dates[i] 

            try:
                product_response = requests.get(product_url) 
                product_soup = BeautifulSoup(product_response.text, "html.parser") 

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø±
                store_name = product_soup.find("a", class_="ProductConfiguration__artistLink--2CvXt").text.strip() 

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù†ØªØ¬
                product_title = product_soup.find("h1", class_="styles__box--2Ufmy styles__text--23E5U styles__display2--3HydH styles__display-block--3kWC4 styles__margin-none--3Ub2V styles__marginTop-xs--2KZR5").text.strip() 

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬
                tag_list = product_soup.find("div", id="work-tags") 
                tag_links = tag_list.find_all("a") 
                tag_data = [tag_link.text.strip().title() for tag_link in tag_links] 

                # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                output = "------------------------------------------\n"
                output += f"ğŸ”¸ï¸Store Name: {store_name}\n"
                output += f"ğŸ”¸ï¸Product Title: {product_title}\n"
                output += f"ğŸ”¸ï¸Tags: {', '.join(tag_data)}.\n"
                output += f"ğŸ”¸ï¸Last Modified Date: {last_modified_date}\n"
                output += f"ğŸ”¸ï¸URL: {product_url}\n"

                # Ø·Ø¨Ø§Ø¹Ø© ÙˆÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                print(output)
                f.write(output)

            except:
                # Ø¥Ø°Ø§ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ØŒ Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
                pass

            # ØªØ£Ø®ÙŠØ± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø¨ÙŠÙ† ÙƒÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø± Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹
            time.sleep(2)
